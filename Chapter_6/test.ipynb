{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers,models,losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "    MPG  Cylinders  Displacement  Horsepower  Weight  Acceleration   \n0  18.0          8         307.0       130.0  3504.0          12.0  \\\n1  15.0          8         350.0       165.0  3693.0          11.5   \n2  18.0          8         318.0       150.0  3436.0          11.0   \n3  16.0          8         304.0       150.0  3433.0          12.0   \n4  17.0          8         302.0       140.0  3449.0          10.5   \n\n   Model Year  Origin  \n0          70       1  \n1          70       1  \n2          70       1  \n3          70       1  \n4          70       1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MPG</th>\n      <th>Cylinders</th>\n      <th>Displacement</th>\n      <th>Horsepower</th>\n      <th>Weight</th>\n      <th>Acceleration</th>\n      <th>Model Year</th>\n      <th>Origin</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>18.0</td>\n      <td>8</td>\n      <td>307.0</td>\n      <td>130.0</td>\n      <td>3504.0</td>\n      <td>12.0</td>\n      <td>70</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>15.0</td>\n      <td>8</td>\n      <td>350.0</td>\n      <td>165.0</td>\n      <td>3693.0</td>\n      <td>11.5</td>\n      <td>70</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>18.0</td>\n      <td>8</td>\n      <td>318.0</td>\n      <td>150.0</td>\n      <td>3436.0</td>\n      <td>11.0</td>\n      <td>70</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>16.0</td>\n      <td>8</td>\n      <td>304.0</td>\n      <td>150.0</td>\n      <td>3433.0</td>\n      <td>12.0</td>\n      <td>70</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>17.0</td>\n      <td>8</td>\n      <td>302.0</td>\n      <td>140.0</td>\n      <td>3449.0</td>\n      <td>10.5</td>\n      <td>70</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 在线下载汽车效能数据集\n",
    "dataset_path = keras.utils.get_file(\"auto-mpg.data\",\"http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\")\n",
    "# 利用 pandas 读取数据集，字段有效能（公里数每加仑），气缸数，排量，马力，重量\n",
    "# 加速度，型号年份，产地\n",
    "column_names = ['MPG','Cylinders','Displacement','Horsepower','Weight',\n",
    " 'Acceleration', 'Model Year', 'Origin']\n",
    "raw_dataset = pd.read_csv(dataset_path, names=column_names,na_values = \"?\", comment='\\t',sep=\" \", skipinitialspace=True)\n",
    "dataset = raw_dataset.copy()\n",
    "# 查看部分数据\n",
    "dataset.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "dataset.isna().sum() # 统计空白数据\n",
    "dataset = dataset.dropna() # 删除空白数据项"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "MPG             0\nCylinders       0\nDisplacement    0\nHorsepower      0\nWeight          0\nAcceleration    0\nModel Year      0\nOrigin          0\ndtype: int64"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isna().sum() # 再次统计空白数据"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "      MPG  Cylinders  Displacement  Horsepower  Weight  Acceleration   \n393  27.0          4         140.0        86.0  2790.0          15.6  \\\n394  44.0          4          97.0        52.0  2130.0          24.6   \n395  32.0          4         135.0        84.0  2295.0          11.6   \n396  28.0          4         120.0        79.0  2625.0          18.6   \n397  31.0          4         119.0        82.0  2720.0          19.4   \n\n     Model Year  USA  Europe  Japan  \n393          82  1.0     0.0    0.0  \n394          82  0.0     1.0    0.0  \n395          82  1.0     0.0    0.0  \n396          82  1.0     0.0    0.0  \n397          82  1.0     0.0    0.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MPG</th>\n      <th>Cylinders</th>\n      <th>Displacement</th>\n      <th>Horsepower</th>\n      <th>Weight</th>\n      <th>Acceleration</th>\n      <th>Model Year</th>\n      <th>USA</th>\n      <th>Europe</th>\n      <th>Japan</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>393</th>\n      <td>27.0</td>\n      <td>4</td>\n      <td>140.0</td>\n      <td>86.0</td>\n      <td>2790.0</td>\n      <td>15.6</td>\n      <td>82</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>394</th>\n      <td>44.0</td>\n      <td>4</td>\n      <td>97.0</td>\n      <td>52.0</td>\n      <td>2130.0</td>\n      <td>24.6</td>\n      <td>82</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>395</th>\n      <td>32.0</td>\n      <td>4</td>\n      <td>135.0</td>\n      <td>84.0</td>\n      <td>2295.0</td>\n      <td>11.6</td>\n      <td>82</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>396</th>\n      <td>28.0</td>\n      <td>4</td>\n      <td>120.0</td>\n      <td>79.0</td>\n      <td>2625.0</td>\n      <td>18.6</td>\n      <td>82</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>397</th>\n      <td>31.0</td>\n      <td>4</td>\n      <td>119.0</td>\n      <td>82.0</td>\n      <td>2720.0</td>\n      <td>19.4</td>\n      <td>82</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 处理类别型数据，其中 origin 列代表了类别 1,2,3,分布代表产地：美国、欧洲、日本\n",
    "# 先弹出(删除并返回)origin 这一列\n",
    "origin = dataset.pop('Origin')\n",
    "# 根据 origin 列来写入新的 3 个列\n",
    "dataset['USA'] = (origin == 1)*1.0\n",
    "dataset['Europe'] = (origin == 2)*1.0\n",
    "dataset['Japan'] = (origin == 3)*1.0\n",
    "dataset.tail() # 查看新表格的后几项"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# 切分为训练集和测试集\n",
    "train_dataset = dataset.sample(frac=0.8,random_state=0)\n",
    "test_dataset = dataset.drop(train_dataset.index)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# 移动 MPG 油耗效能这一列为真实标签 Y\n",
    "train_labels = train_dataset.pop('MPG')\n",
    "test_labels = test_dataset.pop('MPG')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# 查看训练集的输入 X 的统计数据\n",
    "train_stats = train_dataset.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "\n",
    "train_stats = train_stats.transpose() # 转置"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "              count         mean         std     min      25%     50%   \nCylinders     314.0     5.477707    1.699788     3.0     4.00     4.0  \\\nDisplacement  314.0   195.318471  104.331589    68.0   105.50   151.0   \nHorsepower    314.0   104.869427   38.096214    46.0    76.25    94.5   \nWeight        314.0  2990.251592  843.898596  1649.0  2256.50  2822.5   \nAcceleration  314.0    15.559236    2.789230     8.0    13.80    15.5   \nModel Year    314.0    75.898089    3.675642    70.0    73.00    76.0   \nUSA           314.0     0.624204    0.485101     0.0     0.00     1.0   \nEurope        314.0     0.178344    0.383413     0.0     0.00     0.0   \nJapan         314.0     0.197452    0.398712     0.0     0.00     0.0   \n\n                  75%     max  \nCylinders        8.00     8.0  \nDisplacement   265.75   455.0  \nHorsepower     128.00   225.0  \nWeight        3608.00  5140.0  \nAcceleration    17.20    24.8  \nModel Year      79.00    82.0  \nUSA              1.00     1.0  \nEurope           0.00     1.0  \nJapan            0.00     1.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>min</th>\n      <th>25%</th>\n      <th>50%</th>\n      <th>75%</th>\n      <th>max</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Cylinders</th>\n      <td>314.0</td>\n      <td>5.477707</td>\n      <td>1.699788</td>\n      <td>3.0</td>\n      <td>4.00</td>\n      <td>4.0</td>\n      <td>8.00</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>Displacement</th>\n      <td>314.0</td>\n      <td>195.318471</td>\n      <td>104.331589</td>\n      <td>68.0</td>\n      <td>105.50</td>\n      <td>151.0</td>\n      <td>265.75</td>\n      <td>455.0</td>\n    </tr>\n    <tr>\n      <th>Horsepower</th>\n      <td>314.0</td>\n      <td>104.869427</td>\n      <td>38.096214</td>\n      <td>46.0</td>\n      <td>76.25</td>\n      <td>94.5</td>\n      <td>128.00</td>\n      <td>225.0</td>\n    </tr>\n    <tr>\n      <th>Weight</th>\n      <td>314.0</td>\n      <td>2990.251592</td>\n      <td>843.898596</td>\n      <td>1649.0</td>\n      <td>2256.50</td>\n      <td>2822.5</td>\n      <td>3608.00</td>\n      <td>5140.0</td>\n    </tr>\n    <tr>\n      <th>Acceleration</th>\n      <td>314.0</td>\n      <td>15.559236</td>\n      <td>2.789230</td>\n      <td>8.0</td>\n      <td>13.80</td>\n      <td>15.5</td>\n      <td>17.20</td>\n      <td>24.8</td>\n    </tr>\n    <tr>\n      <th>Model Year</th>\n      <td>314.0</td>\n      <td>75.898089</td>\n      <td>3.675642</td>\n      <td>70.0</td>\n      <td>73.00</td>\n      <td>76.0</td>\n      <td>79.00</td>\n      <td>82.0</td>\n    </tr>\n    <tr>\n      <th>USA</th>\n      <td>314.0</td>\n      <td>0.624204</td>\n      <td>0.485101</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>1.0</td>\n      <td>1.00</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>Europe</th>\n      <td>314.0</td>\n      <td>0.178344</td>\n      <td>0.383413</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>Japan</th>\n      <td>314.0</td>\n      <td>0.197452</td>\n      <td>0.398712</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stats"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# 标准化数据\n",
    "def norm(x): # 减去每个字段的均值，并除以标准差\n",
    "     return (x - train_stats['mean']) / train_stats['std']\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "normed_train_data = norm(train_dataset) # 标准化训练集\n",
    "normed_test_data = norm(test_dataset) # 标准化测试集\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(314, 9) (314,)\n"
     ]
    }
   ],
   "source": [
    "print(normed_train_data.shape,train_labels.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78, 9) (78,)\n"
     ]
    }
   ],
   "source": [
    "print(normed_test_data.shape, test_labels.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# 构建Dataset对象\n",
    "train_db = tf.data.Dataset.from_tensor_slices((normed_train_data.values,train_labels.values))\n",
    "# 随机打乱，批量batch\n",
    "train_db = train_db.shuffle(100).batch(32)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "class Network(models.Model):\n",
    "    # 回归网络模型\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        # 创建 3 个全连接层\n",
    "        self.fc1 = layers.Dense(64, activation='relu')\n",
    "        self.fc2 = layers.Dense(64, activation='relu')\n",
    "        self.fc3 = layers.Dense(1)\n",
    "\n",
    "    def call(self, inputs, training=None, mask=None):\n",
    "        # 依次通过三个网络层\n",
    "        x = self.fc1(inputs)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# 创建网络类实例\n",
    "model = Network()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"network\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               multiple                  640       \n",
      "                                                                 \n",
      " dense_1 (Dense)             multiple                  4160      \n",
      "                                                                 \n",
      " dense_2 (Dense)             multiple                  65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,865\n",
      "Trainable params: 4,865\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build构建\n",
    "model.build(input_shape=(4,9))\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# 创建优化器\n",
    "optimizer = keras.optimizers.RMSprop(0.01)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0  step:  0  loss:  50.92118835449219\n",
      "Epoch:  0  step:  1  loss:  267.1707458496094\n",
      "Epoch:  0  step:  2  loss:  66.46539306640625\n",
      "Epoch:  0  step:  3  loss:  84.44633483886719\n",
      "Epoch:  0  step:  4  loss:  47.584228515625\n",
      "Epoch:  0  step:  5  loss:  94.08747863769531\n",
      "Epoch:  0  step:  6  loss:  47.119842529296875\n",
      "Epoch:  0  step:  7  loss:  63.98382568359375\n",
      "Epoch:  0  step:  8  loss:  85.45479583740234\n",
      "Epoch:  0  step:  9  loss:  54.23306655883789\n",
      "Epoch:  10  step:  0  loss:  66.8530502319336\n",
      "Epoch:  10  step:  1  loss:  47.29558563232422\n",
      "Epoch:  10  step:  2  loss:  81.4603042602539\n",
      "Epoch:  10  step:  3  loss:  69.46524047851562\n",
      "Epoch:  10  step:  4  loss:  82.9395523071289\n",
      "Epoch:  10  step:  5  loss:  44.67466354370117\n",
      "Epoch:  10  step:  6  loss:  80.58865356445312\n",
      "Epoch:  10  step:  7  loss:  51.95793533325195\n",
      "Epoch:  10  step:  8  loss:  80.4049072265625\n",
      "Epoch:  10  step:  9  loss:  60.196815490722656\n",
      "Epoch:  20  step:  0  loss:  73.00391387939453\n",
      "Epoch:  20  step:  1  loss:  45.9864387512207\n",
      "Epoch:  20  step:  2  loss:  58.598548889160156\n",
      "Epoch:  20  step:  3  loss:  39.45860290527344\n",
      "Epoch:  20  step:  4  loss:  63.69243621826172\n",
      "Epoch:  20  step:  5  loss:  78.94400024414062\n",
      "Epoch:  20  step:  6  loss:  73.46866607666016\n",
      "Epoch:  20  step:  7  loss:  27.56468963623047\n",
      "Epoch:  20  step:  8  loss:  81.43727111816406\n",
      "Epoch:  20  step:  9  loss:  74.61393737792969\n",
      "Epoch:  30  step:  0  loss:  69.43535614013672\n",
      "Epoch:  30  step:  1  loss:  69.56724548339844\n",
      "Epoch:  30  step:  2  loss:  57.54282760620117\n",
      "Epoch:  30  step:  3  loss:  40.19721984863281\n",
      "Epoch:  30  step:  4  loss:  64.37504577636719\n",
      "Epoch:  30  step:  5  loss:  82.93182373046875\n",
      "Epoch:  30  step:  6  loss:  41.08388137817383\n",
      "Epoch:  30  step:  7  loss:  77.29987335205078\n",
      "Epoch:  30  step:  8  loss:  102.3472671508789\n",
      "Epoch:  30  step:  9  loss:  40.73773193359375\n",
      "Epoch:  40  step:  0  loss:  63.45741653442383\n",
      "Epoch:  40  step:  1  loss:  58.875518798828125\n",
      "Epoch:  40  step:  2  loss:  70.10407257080078\n",
      "Epoch:  40  step:  3  loss:  44.21599197387695\n",
      "Epoch:  40  step:  4  loss:  55.94105911254883\n",
      "Epoch:  40  step:  5  loss:  89.73268127441406\n",
      "Epoch:  40  step:  6  loss:  60.30059051513672\n",
      "Epoch:  40  step:  7  loss:  77.18705749511719\n",
      "Epoch:  40  step:  8  loss:  59.598777770996094\n",
      "Epoch:  40  step:  9  loss:  49.216617584228516\n",
      "Epoch:  50  step:  0  loss:  47.92932891845703\n",
      "Epoch:  50  step:  1  loss:  89.82938385009766\n",
      "Epoch:  50  step:  2  loss:  67.87108612060547\n",
      "Epoch:  50  step:  3  loss:  63.53894805908203\n",
      "Epoch:  50  step:  4  loss:  102.79478454589844\n",
      "Epoch:  50  step:  5  loss:  39.363521575927734\n",
      "Epoch:  50  step:  6  loss:  70.18785095214844\n",
      "Epoch:  50  step:  7  loss:  60.883338928222656\n",
      "Epoch:  50  step:  8  loss:  53.020320892333984\n",
      "Epoch:  50  step:  9  loss:  67.94617462158203\n",
      "Epoch:  60  step:  0  loss:  61.13006591796875\n",
      "Epoch:  60  step:  1  loss:  103.80223083496094\n",
      "Epoch:  60  step:  2  loss:  65.41322326660156\n",
      "Epoch:  60  step:  3  loss:  62.78804016113281\n",
      "Epoch:  60  step:  4  loss:  48.62782287597656\n",
      "Epoch:  60  step:  5  loss:  38.51549530029297\n",
      "Epoch:  60  step:  6  loss:  83.22927856445312\n",
      "Epoch:  60  step:  7  loss:  57.542236328125\n",
      "Epoch:  60  step:  8  loss:  68.37667846679688\n",
      "Epoch:  60  step:  9  loss:  75.08991241455078\n",
      "Epoch:  70  step:  0  loss:  69.30705261230469\n",
      "Epoch:  70  step:  1  loss:  63.46735382080078\n",
      "Epoch:  70  step:  2  loss:  61.931419372558594\n",
      "Epoch:  70  step:  3  loss:  55.35028076171875\n",
      "Epoch:  70  step:  4  loss:  62.422698974609375\n",
      "Epoch:  70  step:  5  loss:  79.75233459472656\n",
      "Epoch:  70  step:  6  loss:  52.51097869873047\n",
      "Epoch:  70  step:  7  loss:  53.614349365234375\n",
      "Epoch:  70  step:  8  loss:  83.45313262939453\n",
      "Epoch:  70  step:  9  loss:  92.37179565429688\n",
      "Epoch:  80  step:  0  loss:  69.19904327392578\n",
      "Epoch:  80  step:  1  loss:  65.6668472290039\n",
      "Epoch:  80  step:  2  loss:  59.978206634521484\n",
      "Epoch:  80  step:  3  loss:  53.41346740722656\n",
      "Epoch:  80  step:  4  loss:  72.93807983398438\n",
      "Epoch:  80  step:  5  loss:  56.44633865356445\n",
      "Epoch:  80  step:  6  loss:  48.049461364746094\n",
      "Epoch:  80  step:  7  loss:  66.52677917480469\n",
      "Epoch:  80  step:  8  loss:  63.52265930175781\n",
      "Epoch:  80  step:  9  loss:  63.97637176513672\n",
      "Epoch:  90  step:  0  loss:  47.12830352783203\n",
      "Epoch:  90  step:  1  loss:  99.23130798339844\n",
      "Epoch:  90  step:  2  loss:  71.80867004394531\n",
      "Epoch:  90  step:  3  loss:  52.334346771240234\n",
      "Epoch:  90  step:  4  loss:  59.17231369018555\n",
      "Epoch:  90  step:  5  loss:  62.35623550415039\n",
      "Epoch:  90  step:  6  loss:  72.24922180175781\n",
      "Epoch:  90  step:  7  loss:  59.118350982666016\n",
      "Epoch:  90  step:  8  loss:  38.29353332519531\n",
      "Epoch:  90  step:  9  loss:  64.5921859741211\n",
      "Epoch:  100  step:  0  loss:  78.13720703125\n",
      "Epoch:  100  step:  1  loss:  49.47865676879883\n",
      "Epoch:  100  step:  2  loss:  51.8667106628418\n",
      "Epoch:  100  step:  3  loss:  62.70011520385742\n",
      "Epoch:  100  step:  4  loss:  55.94718933105469\n",
      "Epoch:  100  step:  5  loss:  46.297706604003906\n",
      "Epoch:  100  step:  6  loss:  50.83619689941406\n",
      "Epoch:  100  step:  7  loss:  72.18095397949219\n",
      "Epoch:  100  step:  8  loss:  67.17367553710938\n",
      "Epoch:  100  step:  9  loss:  89.71820831298828\n",
      "Epoch:  110  step:  0  loss:  58.52911376953125\n",
      "Epoch:  110  step:  1  loss:  75.21015930175781\n",
      "Epoch:  110  step:  2  loss:  54.11857604980469\n",
      "Epoch:  110  step:  3  loss:  63.926483154296875\n",
      "Epoch:  110  step:  4  loss:  64.80288696289062\n",
      "Epoch:  110  step:  5  loss:  53.986961364746094\n",
      "Epoch:  110  step:  6  loss:  41.22393798828125\n",
      "Epoch:  110  step:  7  loss:  73.68038177490234\n",
      "Epoch:  110  step:  8  loss:  61.78462600708008\n",
      "Epoch:  110  step:  9  loss:  78.1677474975586\n",
      "Epoch:  120  step:  0  loss:  62.61699676513672\n",
      "Epoch:  120  step:  1  loss:  58.09348678588867\n",
      "Epoch:  120  step:  2  loss:  50.50724792480469\n",
      "Epoch:  120  step:  3  loss:  71.78140258789062\n",
      "Epoch:  120  step:  4  loss:  56.515586853027344\n",
      "Epoch:  120  step:  5  loss:  64.00643920898438\n",
      "Epoch:  120  step:  6  loss:  73.308837890625\n",
      "Epoch:  120  step:  7  loss:  42.821624755859375\n",
      "Epoch:  120  step:  8  loss:  63.362762451171875\n",
      "Epoch:  120  step:  9  loss:  69.46324920654297\n",
      "Epoch:  130  step:  0  loss:  70.84033203125\n",
      "Epoch:  130  step:  1  loss:  60.213844299316406\n",
      "Epoch:  130  step:  2  loss:  64.26266479492188\n",
      "Epoch:  130  step:  3  loss:  54.43267822265625\n",
      "Epoch:  130  step:  4  loss:  57.1890754699707\n",
      "Epoch:  130  step:  5  loss:  69.40860748291016\n",
      "Epoch:  130  step:  6  loss:  58.823974609375\n",
      "Epoch:  130  step:  7  loss:  59.13192367553711\n",
      "Epoch:  130  step:  8  loss:  78.8138198852539\n",
      "Epoch:  130  step:  9  loss:  49.917476654052734\n",
      "Epoch:  140  step:  0  loss:  77.55140686035156\n",
      "Epoch:  140  step:  1  loss:  58.881980895996094\n",
      "Epoch:  140  step:  2  loss:  35.169334411621094\n",
      "Epoch:  140  step:  3  loss:  43.41303253173828\n",
      "Epoch:  140  step:  4  loss:  62.20246124267578\n",
      "Epoch:  140  step:  5  loss:  61.63630294799805\n",
      "Epoch:  140  step:  6  loss:  60.67135238647461\n",
      "Epoch:  140  step:  7  loss:  46.82262420654297\n",
      "Epoch:  140  step:  8  loss:  76.27010345458984\n",
      "Epoch:  140  step:  9  loss:  98.92184448242188\n",
      "Epoch:  150  step:  0  loss:  54.756797790527344\n",
      "Epoch:  150  step:  1  loss:  84.4748764038086\n",
      "Epoch:  150  step:  2  loss:  48.929588317871094\n",
      "Epoch:  150  step:  3  loss:  56.98369598388672\n",
      "Epoch:  150  step:  4  loss:  93.33271026611328\n",
      "Epoch:  150  step:  5  loss:  59.0806884765625\n",
      "Epoch:  150  step:  6  loss:  55.00859832763672\n",
      "Epoch:  150  step:  7  loss:  46.604270935058594\n",
      "Epoch:  150  step:  8  loss:  60.152992248535156\n",
      "Epoch:  150  step:  9  loss:  70.25635528564453\n",
      "Epoch:  160  step:  0  loss:  78.91934967041016\n",
      "Epoch:  160  step:  1  loss:  51.30839157104492\n",
      "Epoch:  160  step:  2  loss:  79.95173645019531\n",
      "Epoch:  160  step:  3  loss:  56.68438720703125\n",
      "Epoch:  160  step:  4  loss:  60.52117156982422\n",
      "Epoch:  160  step:  5  loss:  72.41997528076172\n",
      "Epoch:  160  step:  6  loss:  58.447303771972656\n",
      "Epoch:  160  step:  7  loss:  77.86449432373047\n",
      "Epoch:  160  step:  8  loss:  56.03943634033203\n",
      "Epoch:  160  step:  9  loss:  51.11960983276367\n",
      "Epoch:  170  step:  0  loss:  95.65542602539062\n",
      "Epoch:  170  step:  1  loss:  66.15898132324219\n",
      "Epoch:  170  step:  2  loss:  58.497947692871094\n",
      "Epoch:  170  step:  3  loss:  49.7916259765625\n",
      "Epoch:  170  step:  4  loss:  53.04706573486328\n",
      "Epoch:  170  step:  5  loss:  48.55234146118164\n",
      "Epoch:  170  step:  6  loss:  42.41461944580078\n",
      "Epoch:  170  step:  7  loss:  45.46337127685547\n",
      "Epoch:  170  step:  8  loss:  101.50456237792969\n",
      "Epoch:  170  step:  9  loss:  83.57567596435547\n",
      "Epoch:  180  step:  0  loss:  59.82875061035156\n",
      "Epoch:  180  step:  1  loss:  46.365543365478516\n",
      "Epoch:  180  step:  2  loss:  44.44615936279297\n",
      "Epoch:  180  step:  3  loss:  65.14094543457031\n",
      "Epoch:  180  step:  4  loss:  82.79678344726562\n",
      "Epoch:  180  step:  5  loss:  68.97477722167969\n",
      "Epoch:  180  step:  6  loss:  70.49481201171875\n",
      "Epoch:  180  step:  7  loss:  66.31049346923828\n",
      "Epoch:  180  step:  8  loss:  63.871192932128906\n",
      "Epoch:  180  step:  9  loss:  46.41065216064453\n",
      "Epoch:  190  step:  0  loss:  69.14820098876953\n",
      "Epoch:  190  step:  1  loss:  57.694820404052734\n",
      "Epoch:  190  step:  2  loss:  59.62712097167969\n",
      "Epoch:  190  step:  3  loss:  57.88102722167969\n",
      "Epoch:  190  step:  4  loss:  45.409542083740234\n",
      "Epoch:  190  step:  5  loss:  79.76775360107422\n",
      "Epoch:  190  step:  6  loss:  51.64268493652344\n",
      "Epoch:  190  step:  7  loss:  52.07158660888672\n",
      "Epoch:  190  step:  8  loss:  96.17766571044922\n",
      "Epoch:  190  step:  9  loss:  55.25154495239258\n"
     ]
    }
   ],
   "source": [
    "# 200次epoch\n",
    "for epoch in range(200):\n",
    "    for step,(x,y) in enumerate(train_db):\n",
    "        # 梯度记录器\n",
    "        with tf.GradientTape() as tape:\n",
    "            out = model(x)\n",
    "            loss =tf.reduce_mean(losses.MSE(y,out))\n",
    "            mae = tf.reduce_mean(losses.MAE(y,out))\n",
    "        if epoch%10 == 0:\n",
    "            print(\"Epoch: \",epoch,\" step: \",step,\" loss: \",float(loss))\n",
    "        # 计算梯度并更新\n",
    "        grads = tape.gradient(loss,model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}